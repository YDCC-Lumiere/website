{{ define "index" }}
{{ template "header" }}
<div class="container">
    <div class="row">
        <div class="col-10 offset-md-1 fs-3">
            <p class="display-1">Lumière</p>
            <p class="lead fs-4">Shine bright like a diamond</p>
            <hr>
            <p>
                In the emerging age of technologies, anything can be simulated, anything
                is <b>maleable</b>. So, things like
                <figure class="text-center">
                    <blockquote class="blockquote fs-2">
                        <p>Seeing is believing</p>
                    </blockquote>
                </figure>

                are hardly certain.
            </p>
            <p>
                To tackle this harsh but truthful reality, we aimed to <i>fight fire
                with fire</i>, to counter-attack the overgrowing forces of generative AIs,
                with its own arch enemies, they themselves.
            </p>
            <p>
                Harnessing the power of <abbr title="Generate Adversarial Network">GANs</abbr>,
                we trained our model to learn from the attacker's mistakes. In a
                seemingly endless loop of playing cat-and-mouse with the opponent,
                our model gets more and more acquaintained with the adversarial's
                techniques. Solely for the goal of bringing the end to maliciously
                using the great powers for the bad deed, these AI models keeps going forward.
            </p>

            <figure class="text-center">
                <blockquote class="blockquote fs-2">...</blockquote>
            </figure>

            <p class="display-6">Epilogue</p>
            <hr>
            <p>
                At <b>Lumière</b>, we help organizations with few or little asset
                to build an autonomous risk management team. We solely focus on
                the malicious usage of generative AIs like face or voice recording
                forgery.
            </p>
            <p>
                In cases where business applies marketing strategies to welcome
                new users, a bundle of free gifts are sent. If an attacker exploits
                this method to gain more profit, companies lose their money for nothing.
            </p>
            <p>
                The solution consists of 2 methods: face and voice recording verification.
                <br>
                For <b>face</b> recordings, the media file is tested against multiple
                AI models that are pretrained to tackcle a specific type of deepfake application.
                This technique is implemented based on our member's published paper
                in <mark>TODO</mark>.
                <br>
                For <b>voice</b> recordings, we apply a different strategy. We first store
                a <i>ground-truth</i> recording of a user. When our client apps require
                the users to verify that they're not artificially generated, a new
                voice recording is tested against the <i>ground-truth</i> data to
                make sure that the user making actions is that same person from the first start.
            </p>
        </div>
    </div>
</div>
{{ template "footer" }}
{{ end }}
